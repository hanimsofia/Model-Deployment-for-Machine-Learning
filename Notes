Notes

Deploy the best-performing model using a platform like Streamlit, Flask, Django, and a  cloud service google vertex AI 

Description of Deployment Options:
1. Streamlit: A simple web app framework for Python. A script is created that loads the model and allows users to input data and see predictions directly in the web app.
2. Flask: A more flexible Python web framework that allows for the creation of RESTful APIs. Endpoints is set up for clients to interact with your model via HTTP requests.

The sample of data modelling retrieved from: https://www.kaggle.com/code/vaibhavtalekar/xgboost-classifier-99-cross-validation-accuracy

1. Streamlit

pip install xgboost

#Python pickle module, which is a common way to serialize Python objects:
import pickle
# Assuming 'pipeline' is the target trained model
with open('model.pkl', 'wb') as file:
    pickle.dump(pipeline, file)

pip install streamlit

# Create Streamlit Script (streamlit_app.py) 
# Script assumes model and any necessary pre-processing or post-processing functions are defined within the script or imported from other modules. Save this script in the same directory as saved model file (model.pkl)

import streamlit as st
import pandas as pd
import pickle

# Load your trained model
with open('model.pkl', 'rb') as file:
    model = pickle.load(file)

# Create a simple Streamlit application
st.title('Credit Card Fraud Detection')

# Assuming the input features directly for prediction
features = st.text_input('Enter features separated by commas')

if st.button('Predict'):
    # Convert input string to numpy array
    features = pd.DataFrame([float(x) for x in features.split(',')]).T
    # Use the model to make predictions
    prediction = model.predict(features)
    st.write('Prediction:', 'Fraud' if prediction[0] else 'Not Fraud')


# Run Streamlit App

streamlit run credit_card_fraud_detection.py

2. Flask Framework

pip install flask

# Create Flask App (flask_app.py)

from flask import Flask, request, jsonify
import pickle

app = Flask(__name__)

# Load your trained model
model = pickle.load(open('model.pkl', 'rb'))

@app.route('/predict', methods=['POST'])
def predict():
    data = request.get_json(force=True)
    prediction = model.predict([data['features']])
    return jsonify(prediction.tolist())

if __name__ == '__main__':
    app.run(debug=True)


python flask_app.py


curl -X POST http://127.0.0.1:5000/predict -H "Content-Type: application/json" -d "{\"features\": \"12,-2.791854766,-0.327770757,1.641750161,1.767472744,-0.136588446,0.807596468,-0.42291139,-1.907107476,0.755712908,1.151086988,0.844555471,0.792943952,0.370448093,-0.734975106,0.40679571,-0.303057624,-0.155868715,0.778265457,2.221868014,-1.582122044,1.151663048,0.222181966,1.020586204,0.028316651,-0.232746324,-0.235557218,-0.164777512,-0.030153637,58.8\"}"


